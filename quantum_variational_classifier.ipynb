{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Quantum Variational Classifier\n",
    "\n",
    "This tutorial discusses how a quantum computer can be used to solve a classification task.<br>\n",
    "The example is based on the following paper:\n",
    "<br>\n",
    "<br>\n",
    "<b>Supervised learning with quantum enhanced feature spaces</b><br>\n",
    "Vojtech Havlicek, Antonio D. Corcoles, Kristan Temme, Aram W. Harrow, Abhinav  Kandala, Jerry M. Chow, and Jay  M. Gambetta<br>\n",
    "<a href=\"https://arxiv.org/abs/1804.11326\">arXiv:1804.11326 (2018)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from svm.datasets import *\n",
    "from qiskit_aqua.input import get_input_instance\n",
    "from qiskit_aqua import run_algorithm\n",
    "from qiskit import QuantumRegister, ClassicalRegister, QuantumCircuit\n",
    "from qiskit import execute\n",
    "from qiskit.tools.visualization import matplotlib_circuit_drawer, circuit_drawer\n",
    "\n",
    "from qiskit_aqua.utils.optimizers.spsa import SPSA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# define function to draw circuits\n",
    "# drawer = lambda qc: circuit_drawer(qc, basis='u1,u2,u3,id,cx,cz,h,x,ry,rz,cz')\n",
    "drawer = lambda qc: matplotlib_circuit_drawer(qc, basis='u1,u2,u3,id,cx,cz,h,x,ry,rz,cz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Before we can train the Quantum Variational Classifier, we have to load the data set that we are interested in and split it into a training and a test set.\n",
    "<br>\n",
    "Note that the ad hoc data set is constructed suitably for the purpose of illustration.\n",
    "<br>\n",
    "<br>\n",
    "<b>Exercise:</b><br>\n",
    "Feel free to train and test the classifier with the alternatively given training data set:<br>\n",
    "<a href=\"https://archive.ics.uci.edu/ml/datasets/wine\">UCI Machine Learning Repository - Wine Data Set</a><br>\n",
    "To switch between the data sets set the <b>use_adhoc_dataset</b> to True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of training data set\n",
    "training_size = 20\n",
    "\n",
    "# size of test data set\n",
    "test_size = 10\n",
    "\n",
    "# dimension of data sets\n",
    "n = 2\n",
    "\n",
    "# construct training and test data\n",
    "# set the following flag to True for the first data set and to False for the second dataset\n",
    "use_adhoc_dataset = True\n",
    "if use_adhoc_dataset:\n",
    "    # first (artifical) data set to test the classifier\n",
    "    training_input, test_input, class_labels = \\\n",
    "            ad_hoc_data(training_size=training_size, test_size=test_size, n=n, gap=0.3, PLOT_DATA=True)\n",
    "else:\n",
    "    # second data set to test the classifier\n",
    "    training_input, test_input, class_labels = \\\n",
    "            Wine(training_size=training_size, test_size=test_size, n=n, PLOT_DATA=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum Feature Map\n",
    "\n",
    "The Quantum Feature Map $\\cal{U}_{\\Phi(\\vec{x})}$ is a quantum circuit parametrized by a classical input datapoint $\\vec{x}$.\n",
    "Thus, $\\cal{U}$ maps $\\vec{x}$ to the quantum feature space whose dimension is exponential in the number of qubits.\n",
    "In this tutorial we use the following quantum feature map:\n",
    "<img src=\"svm/feature_map.png\">\n",
    "<br>\n",
    "where\n",
    "### $$U_{\\Phi(\\vec{x})} = e^{i\\left(x_1 Z \\otimes I + x_2 I \\otimes Z + x_1x_2Z \\otimes Z \\right)}$$\n",
    "\n",
    "The classical data sample $\\vec{x}$ is loaded by applying the Quantum Feature Map onto the initial quantum state $|0{\\rangle}^{\\otimes n}$:\n",
    "### $$|\\phi(\\vec{x})\\rangle = \\cal{U}_{\\Phi(\\vec{x})}|0{\\rangle}^{\\otimes n}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_map(x, q):\n",
    "    \n",
    "    # initialize quantum circuit\n",
    "    qc = QuantumCircuit(q)\n",
    "    \n",
    "    # apply hadamards and U_Phi twice\n",
    "    for _ in range(2):\n",
    "        \n",
    "        # apply the hadamard and Z-rotatiion to all qubits\n",
    "        for i in range(x.shape[0]):\n",
    "            qc.h(q[i])\n",
    "            qc.rz(2 * x[i], q[i])\n",
    "        \n",
    "        # apply the two qubit gate\n",
    "        qc.cx(q[0], q[1])\n",
    "        qc.rz(2*(np.pi-x[0])*(np.pi-x[1]), q[1])\n",
    "        qc.cx(q[0], q[1])\n",
    "\n",
    "    # return quantum circuit\n",
    "    return qc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use a classical vector, for instance $\\begin{pmatrix} 1.5 \\\\ 0.3 \\end{pmatrix}$ to apply the quantum feature map onto the quantum state $|0{\\rangle}^{\\otimes 2}$, analyze the resulting statevector and plot the corresponding quantum circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize quantum register\n",
    "num_qubits = 2\n",
    "qr = QuantumRegister(num_qubits)\n",
    "\n",
    "# initialize test data (x1, x2)\n",
    "data = np.asarray([1.5, 0.3])\n",
    "\n",
    "# get quantum circuit\n",
    "qc_feature_map = feature_map(data, qr)\n",
    "\n",
    "# draw circuit\n",
    "drawer(qc_feature_map)\n",
    "\n",
    "# simulate using local statevector simulator\n",
    "job_sim = execute(qc_feature_map, 'local_statevector_simulator', shots=1)\n",
    "sim_results = job_sim.result()\n",
    "print('simulation: ', sim_results)\n",
    "print('statevector: ', np.round(sim_results.get_statevector(), decimals=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Form\n",
    "\n",
    "The variational form is similar to an artifical neural network:\n",
    "<br>\n",
    "The quantum circuit receives input data, processes it through multiple layers of  parametrized quantum gates and is trained by adjusting the parameters (weights).\n",
    "<br>\n",
    "It should be noted that in order to optimize the parameters, the outcome of the Quantum Variational Circuit must be measured. The measurement outcome corresponds to classical bits which can be integrated in an optimization algorithm, such as gradient descent. \n",
    "<br>\n",
    "<br>\n",
    "In this tutorial we use the following Variational Form:\n",
    "<br>\n",
    "<img src=\"svm/variational_form.png\">\n",
    "<br>\n",
    "The single qubit rotations denoted by $\\theta_{i,j}$ correspond to Z-rotations and Y-rotations and the entangler block $U_{ent}$ consists of controlled-Z gates.\n",
    "Further, the parameter $d$ denotes the depth of the Variational Circuit, i.e. the number of repitions of entangler blocks and single qubit rotation layers.\n",
    "<br>\n",
    "<br>\n",
    "<b>Exercise:</b><br>\n",
    "See how the classification performance changes when you modify the types of gates used within the quantum circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variational_form(q, params, depth):\n",
    "    \n",
    "    # initialize quantum circuit\n",
    "    qc = QuantumCircuit(q)\n",
    "    \n",
    "    # first set of rotations\n",
    "    param_idx = 0\n",
    "    for qubit in range(2):\n",
    "        qc.ry(params[param_idx], q[qubit])\n",
    "        qc.rz(params[param_idx+1], q[qubit])\n",
    "        param_idx += 2\n",
    "\n",
    "    # entangler blocks and succeeding rotations\n",
    "    for block in range(depth):\n",
    "        qc.cz(q[0], q[1])\n",
    "        for qubit in range(2):\n",
    "            qc.ry(params[param_idx], q[qubit])\n",
    "            qc.rz(params[param_idx+1], q[qubit])\n",
    "            param_idx += 2\n",
    "    \n",
    "    # return quantum circuit\n",
    "    return qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize quantum register\n",
    "num_qubits = 2\n",
    "qr = QuantumRegister(num_qubits)\n",
    "\n",
    "# set depth, i.e. number of entangler blocks and rotations (after the initial rotation)\n",
    "depth = 2\n",
    "params = [0.5,-0.3, 0.2, 0.6]*(depth+1)\n",
    "qc_variational_form = variational_form(qr, params, depth)\n",
    "\n",
    "# draw circuit\n",
    "drawer(qc_variational_form)\n",
    "\n",
    "# simulate using local statevector simulator\n",
    "job_sim = execute(qc_variational_form, 'local_statevector_simulator', shots=1)\n",
    "sim_results = job_sim.result()\n",
    "print('simulation: ', sim_results)\n",
    "print('statevector: ', np.round(sim_results.get_statevector(), decimals=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Quantum Variational Classifier\n",
    "\n",
    "Before we can combine the previously introduced components to the quantum variational classifier, we need to introduce some more helper functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.  Assign a label to the measurement outcome \n",
    "We use the parity function to assign a class label to the measurement outcomes which are given as bit strings. In explicit, a measurement consisting of an even number of '1's is mapped to the first class, and a measurement outcome consisting of an odd number of '1's is mapped to the second class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_label(bit_string, class_labels):\n",
    "    hamming_weight = sum([int(k) for k in list(bit_string)])\n",
    "    is_odd_parity = hamming_weight & 1\n",
    "    if is_odd_parity:\n",
    "        return class_labels[1]\n",
    "    else:\n",
    "        return class_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigns a label \n",
    "assign_label('01', class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Map the counts of multiple shots to probabilities for the classes\n",
    "After running the same circuit many times, we derive the empirical probabilities of assigning the first or second class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_probabilities(counts, class_labels):\n",
    "    shots = sum(counts.values())\n",
    "    result = {class_labels[0]: 0, \n",
    "              class_labels[1]: 0}\n",
    "    for key, item in counts.items():\n",
    "        label = assign_label(key, class_labels)\n",
    "        result[label] += counts[key]/shots\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_probabilities({'00' : 10, '01': 10}, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Combine everything to build the classifier\n",
    "We combine the feature map, the variational circuit, and the label assignment to construct our (untrained) classifier.\n",
    "<br>\n",
    "Note that the classifier is already constructed in such a way that it is able to process a list of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifier_circuit(x, params, depth):\n",
    "    \n",
    "    q = QuantumRegister(2)\n",
    "    c = ClassicalRegister(2)    \n",
    "    qc = QuantumCircuit(q, c)\n",
    "\n",
    "    qc_feature_map = feature_map(x, q)\n",
    "    qc_variational_form = variational_form(q, params, depth)\n",
    "\n",
    "    qc += qc_feature_map\n",
    "    qc += qc_variational_form\n",
    "\n",
    "    qc.measure(q, c)\n",
    "    \n",
    "    return qc\n",
    "\n",
    "def classify(x_list, params, class_labels, depth=2, shots=100):\n",
    "    \n",
    "    qc_list = []\n",
    "    for x in x_list:\n",
    "        qc = classifier_circuit(x, params, depth)\n",
    "        qc_list += [qc]\n",
    "        \n",
    "    jobs = execute(qc_list, \"local_qasm_simulator\", shots=shots)\n",
    "    \n",
    "    probs = []\n",
    "    for qc in qc_list:\n",
    "        counts = jobs.result().get_counts(qc)\n",
    "        prob = return_probabilities(counts, class_labels)\n",
    "        probs += [prob]\n",
    "            \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw classifier circuit\n",
    "qc = classifier_circuit(np.asarray([0.5, 0.5]), params, depth)\n",
    "drawer(qc)\n",
    "\n",
    "# classify test data point (using random parameters constructed earlier)\n",
    "x = np.asarray([[0.5, 0.5]])\n",
    "classify(x, params, class_labels, depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Assign a cost value to the estimation probabilities\n",
    "Given a training data point and the corresponding training class label, we can calculate a cost value which represents the probability of correct/false classification. \n",
    "<br>\n",
    "We only need a singificant bias towards the correct classification and, thus, use the sigmoid function to evaluate the cost value (error probability).<br>\n",
    "The function is close to zero if the probability of assigning the correct class is close to one, and close to one otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost_estimate_sigmoid(probs, expected_label):\n",
    "\n",
    "    p = probs.get(expected_label)\n",
    "    sig = None\n",
    "    if np.isclose(p, 0.0):\n",
    "        sig = 1\n",
    "    elif np.isclose(p, 1.0):\n",
    "        sig = 0\n",
    "    else:\n",
    "        denominator = np.sqrt(2*p*(1-p))\n",
    "        x = np.sqrt(200)*(0.5-p)/denominator\n",
    "        sig = 1/(1+np.exp(-x))\n",
    "\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 20)\n",
    "y = [cost_estimate_sigmoid({'A': x_, 'B': 1-x_}, 'A') for x_ in x]\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('Probability of assigning the correct class')\n",
    "plt.ylabel('Cost value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Evaluate the overall performance for the training set\n",
    "We compute the average cost value over all training data points and use this as the objective function to train our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cost_function(training_input, class_labels, params, depth=2, shots=100, print_value=False):\n",
    "    \n",
    "    # map training input to list of labels and list of samples\n",
    "    cost = 0\n",
    "    training_labels = []\n",
    "    training_samples = []\n",
    "    for label, samples in training_input.items():\n",
    "        for sample in samples:\n",
    "            training_labels += [label]\n",
    "            training_samples += [sample]\n",
    "        \n",
    "    # classify all samples\n",
    "    probs = classify(training_samples, params, class_labels, depth)\n",
    "    \n",
    "    # evaluate costs for all classified samples\n",
    "    for i, prob in enumerate(probs):\n",
    "        cost += cost_estimate_sigmoid(prob, training_labels[i])\n",
    "    cost /= len(training_samples)\n",
    "    \n",
    "    # print resulting objective function\n",
    "    if print_value:\n",
    "        print('%.4f' % cost)\n",
    "    \n",
    "    # return objective value\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_function(training_input, class_labels, params, depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the classifier\n",
    "\n",
    "Training the classifier corresponds to an optimization task. Explicitly, we want to minimize the cost value (sigmoid function) such that the classifier manages to properly label the given data.\n",
    "<br>\n",
    "<br>\n",
    "<b>Exercise:</b><br>\n",
    "See how the classification performance changes when you modify the depth of the variational form, the number of shots or number of trials.<br>\n",
    "What's the best that you can achieve for the adhoc data set and the Wine data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set depth of variational form\n",
    "depth = 2\n",
    "\n",
    "# set number of shots to evaluate the classification circuit\n",
    "shots = 100\n",
    "\n",
    "# set number of iterations for the optimization algorithm\n",
    "# (SPSA evaluates the objective function twice per iteration)\n",
    "max_trials = 25\n",
    "\n",
    "# setup the optimizer\n",
    "optimizer = SPSA()\n",
    "spsa_params = np.asarray([4.0, 0.1, 0.602, 0.101, 0.0])\n",
    "optimizer.init_args(max_trials=max_trials, parameters=spsa_params)\n",
    "\n",
    "# define objective function for training\n",
    "objective_function = lambda params: cost_function(training_input, class_labels, params, depth, shots, print_value=True)\n",
    "\n",
    "# randomly initialize the parameters\n",
    "init_params = 2*np.pi*np.random.rand(num_qubits*(depth+1)*2)\n",
    "\n",
    "# train classifier\n",
    "opt_params, value, _ = optimizer.optimize(len(init_params), objective_function, initial_point=init_params)\n",
    "\n",
    "# print results\n",
    "print()\n",
    "print('opt_params:', opt_params)\n",
    "print('opt_value: ', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the trained classifier\n",
    "\n",
    "To check how well we could train the classifier, we evaluate the classification performance on the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# collect coordinates of test data\n",
    "test_label_0_x = [x[0] for x in test_input[class_labels[0]]]\n",
    "test_label_0_y = [x[1] for x in test_input[class_labels[0]]]\n",
    "test_label_1_x = [x[0] for x in test_input[class_labels[1]]]\n",
    "test_label_1_y = [x[1] for x in test_input[class_labels[1]]]\n",
    "\n",
    "# initialize lists for misclassified datapoints\n",
    "test_label_misclassified_x = []\n",
    "test_label_misclassified_y = []\n",
    "\n",
    "# evaluate test data\n",
    "for label, samples in test_input.items():\n",
    "    \n",
    "    # classify samples \n",
    "    results = classify(samples, opt_params, class_labels, depth, shots=shots)\n",
    "    \n",
    "    # analyze results\n",
    "    for i, result in enumerate(results):\n",
    "        \n",
    "        # assign label\n",
    "        assigned_label = class_labels[np.argmax([p for p in result.values()])]\n",
    "        print('----------------------------------------------------')\n",
    "        print('Data point:    ', samples[i])\n",
    "        print('Label:         ', label)\n",
    "        print('Assigned:      ', assigned_label)\n",
    "        print('Probabilities: ', result)\n",
    "        \n",
    "        if label != assigned_label:\n",
    "            print('Classification:', 'INCORRECT')\n",
    "            test_label_misclassified_x += [samples[i][0]]\n",
    "            test_label_misclassified_y += [samples[i][1]]\n",
    "        else:\n",
    "            print('Classification:', 'CORRECT')\n",
    "        \n",
    "# compute fraction of misclassified samples\n",
    "total = len(test_label_0_x) + len(test_label_1_x)\n",
    "num_misclassified = len(test_label_misclassified_x)\n",
    "print()\n",
    "print(100*(1-num_misclassified/total), \"% of the test data was correctly classified!\")\n",
    "\n",
    "# plot results\n",
    "plt.figure()\n",
    "plt.scatter(test_label_0_x, test_label_0_y, c='b', label=class_labels[0], linewidths=5)\n",
    "plt.scatter(test_label_1_x, test_label_1_y, c='g', label=class_labels[1], linewidths=5)\n",
    "plt.scatter(test_label_misclassified_x, test_label_misclassified_y, linewidths=20, s=1, facecolors='none', edgecolors='r')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# How to call the Quantum Variational Classifier in Qiskit Aqua\n",
    "\n",
    "The Qiskit Aqua environment provides a method to call the Quantum Variational Classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'problem': {'name': 'svm_classification'},\n",
    "    'backend': {'name': 'local_qasm_simulator', 'shots': 100},\n",
    "    'algorithm': {\n",
    "        'name': 'SVM_Variational',\n",
    "        'circuit_depth': 3,\n",
    "        'print_info': True\n",
    "    },\n",
    "    'optimizer': {\n",
    "        'name': 'SPSA',\n",
    "        'max_trials': 100,\n",
    "        'save_steps': 10\n",
    "    }\n",
    "}\n",
    "\n",
    "algo_input = get_input_instance('SVMInput')\n",
    "algo_input.training_dataset = training_input\n",
    "algo_input.test_dataset = test_input\n",
    "result = run_algorithm(params, algo_input)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
